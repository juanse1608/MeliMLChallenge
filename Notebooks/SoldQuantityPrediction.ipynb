{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Importar-Librerías\" data-toc-modified-id=\"Importar-Librerías-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Importar Librerías</a></span></li><li><span><a href=\"#Funciones-y-Clases\" data-toc-modified-id=\"Funciones-y-Clases-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Funciones y Clases</a></span></li><li><span><a href=\"#Preprocesamiento-de-Datos\" data-toc-modified-id=\"Preprocesamiento-de-Datos-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Preprocesamiento de Datos</a></span><ul class=\"toc-item\"><li><span><a href=\"#Construcción-del-Dataset-de-Productos\" data-toc-modified-id=\"Construcción-del-Dataset-de-Productos-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Construcción del Dataset de Productos</a></span><ul class=\"toc-item\"><li><span><a href=\"#Lectura-de-los-Datos\" data-toc-modified-id=\"Lectura-de-los-Datos-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Lectura de los Datos</a></span></li><li><span><a href=\"#Transformación-de-los-Datos\" data-toc-modified-id=\"Transformación-de-los-Datos-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Transformación de los Datos</a></span></li></ul></li><li><span><a href=\"#Selección-de-Predictores\" data-toc-modified-id=\"Selección-de-Predictores-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Selección de Predictores</a></span></li><li><span><a href=\"#Estandarización,-OneHotEncoding-y-Train-Test-Split\" data-toc-modified-id=\"Estandarización,-OneHotEncoding-y-Train-Test-Split-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Estandarización, OneHotEncoding y Train-Test Split</a></span></li></ul></li><li><span><a href=\"#Modelos-de-Predicción---Sold-Quantity\" data-toc-modified-id=\"Modelos-de-Predicción---Sold-Quantity-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Modelos de Predicción - Sold Quantity</a></span><ul class=\"toc-item\"><li><span><a href=\"#XGBoost-(Gradient-Boosting-Trees)\" data-toc-modified-id=\"XGBoost-(Gradient-Boosting-Trees)-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>XGBoost (Gradient Boosting Trees)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Análisis-de-Resultados-y-Rendimiento\" data-toc-modified-id=\"Análisis-de-Resultados-y-Rendimiento-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>Análisis de Resultados y Rendimiento</a></span></li></ul></li><li><span><a href=\"#NNs-(Redes-Neuronales)\" data-toc-modified-id=\"NNs-(Redes-Neuronales)-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>NNs (Redes Neuronales)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Análisis-de-Resultados-y-Rendimiento\" data-toc-modified-id=\"Análisis-de-Resultados-y-Rendimiento-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>Análisis de Resultados y Rendimiento</a></span></li></ul></li><li><span><a href=\"#Random-Forest-(Bosques-Aleatorios)\" data-toc-modified-id=\"Random-Forest-(Bosques-Aleatorios)-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Random Forest (Bosques Aleatorios)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Análisis-de-Resultados-y-Rendimiento\" data-toc-modified-id=\"Análisis-de-Resultados-y-Rendimiento-4.3.1\"><span class=\"toc-item-num\">4.3.1&nbsp;&nbsp;</span>Análisis de Resultados y Rendimiento</a></span></li></ul></li><li><span><a href=\"#Stacked-Model\" data-toc-modified-id=\"Stacked-Model-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Stacked Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Análisis-de-Resultados-y-Rendimiento\" data-toc-modified-id=\"Análisis-de-Resultados-y-Rendimiento-4.4.1\"><span class=\"toc-item-num\">4.4.1&nbsp;&nbsp;</span>Análisis de Resultados y Rendimiento</a></span></li></ul></li></ul></li><li><span><a href=\"#Conclusiones-y-Reflexiones\" data-toc-modified-id=\"Conclusiones-y-Reflexiones-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Conclusiones y Reflexiones</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sold Quantity Prediction\n",
    "\n",
    "El propósito de este notebook es construir una serie de modelos de predicción para estimar la variable `ITEM_SOLD_QUANTITY` de un item de [Mercado Libre](https://www.mercadolibre.com.co/) con el dataset construido en [`MeliMLChallenge/Notebook/ApiPullingData.ipynb`](https://github.com/juanse1608/MeliMLChallenge/blob/main/Notebooks/ApiPullingData.ipynb).\n",
    "\n",
    "Se recuerda que el dataset consta de __14574__ items (tratanto de tener la misma cantidad para cada una de las categorías de ítems de Meli Colombia) y __50__ variables asociadas al ítem, su vendedor y su envío."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T15:46:35.183584Z",
     "start_time": "2021-03-16T15:46:35.174207Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div#notebook-container{width: 60%;}div#menubar-container{width: 65%;} div#maintoolbar-container{width: 99%;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cambia el ancho de las celdas\n",
    "from IPython.display import HTML, display\n",
    "display(HTML(data=\"\"\"<style>div#notebook-container{width: 60%;}div#menubar-container{width: 65%;} div#maintoolbar-container{width: 99%;}</style>\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T15:46:39.651971Z",
     "start_time": "2021-03-16T15:46:35.185933Z"
    }
   },
   "outputs": [],
   "source": [
    "# Procesamiento de datos\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import itertools as it\n",
    "import requests\n",
    "\n",
    "# Visualización\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# ML y DS\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import XGBRFRegressor\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones y Clases\n",
    "\n",
    "Esta sección tiene las funciones y clases creadas que se usarán a los largo de este notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T15:46:39.656173Z",
     "start_time": "2021-03-16T15:46:39.653759Z"
    }
   },
   "outputs": [],
   "source": [
    "# Funcion que en encuentra el valor mas cercano de un array a un valor \n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T15:46:39.664747Z",
     "start_time": "2021-03-16T15:46:39.658363Z"
    }
   },
   "outputs": [],
   "source": [
    "#Let's plot the confusion matrix\n",
    "#Function which objective is to plot in a fancy way the confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "#     classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        #print(\"Normalized confusion matrix\")\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (10,10))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=0, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de Datos\n",
    "\n",
    "En esta sección se realiza un proceso general de limpieza y organización de los datos previo a la exploración de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Construcción del Dataset de Productos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Lectura de los Datos\n",
    " \n",
    "En esta subsección se leen el dataset de productos, se imprimen sus dimensiones, sus columnas y se mencionan sus tipos de variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T15:46:39.797237Z",
     "start_time": "2021-03-16T15:46:39.666914Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAS DIMENSIONES DE LA BASE DE PRODUCTOS SON: (14574, 50)\n"
     ]
    }
   ],
   "source": [
    "# Se lee el .csv con el datset construido\n",
    "products = pd.read_csv('../Data/Datasets/PRODUCTOS.csv')\n",
    "products.columns = products.columns.str.upper() # Pone los nombres de las columnas en mayusculas\n",
    "print('LAS DIMENSIONES DE LA BASE DE PRODUCTOS SON: {}'.format(products.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T15:46:39.802209Z",
     "start_time": "2021-03-16T15:46:39.798705Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ITEM_ID', 'ITEM_SITE_ID', 'ITEM_TITLE', 'ITEM_PRICE',\n",
       "       'ITEM_SALE_PRICE', 'ITEM_CURRENCY_ID', 'ITEM_AVAILABLE_QUANTITY',\n",
       "       'ITEM_SOLD_QUANTITY', 'ITEM_BUYING_MODE', 'ITEM_LISTING_TYPE_ID',\n",
       "       'ITEM_STOP_TIME', 'ITEM_CONDITION', 'ITEM_PERMALINK', 'ITEM_THUMBNAIL',\n",
       "       'ITEM_THUMBNAIL_ID', 'ITEM_ACCEPTS_MERCADOPAGO', 'ITEM_ORIGINAL_PRICE',\n",
       "       'ITEM_CATEGORY_ID', 'ITEM_OFFICIAL_STORE_ID', 'ITEM_DOMAIN_ID',\n",
       "       'ITEM_CATALOG_PRODUCT_ID', 'ITEM_ORDER_BACKEND',\n",
       "       'ITEM_USE_THUMBNAIL_ID', 'SEARCH_CATEGORY_ID', 'SEARCH_CATEGORY_NAME',\n",
       "       'SEARCH_OFFSET', 'SELLER_ID', 'SELLER_REP_TRANSACTIONS_TOTAL',\n",
       "       'SELLER_REP_TRANSACTIONS_CANCELED', 'SELLER_REP_RATING_NEG',\n",
       "       'SELLER_REP_RATING_POS', 'SELLER_REP_RATING_NEU',\n",
       "       'SELLER_TRANSACTIONS_COMPLETED', 'SELLER_STATUS',\n",
       "       'SELLER_METRICS_CLAIMS_RATE', 'SELLER_METRICS_CLAIMS_VALUE',\n",
       "       'SELLER_METRICS_CLAIMS_PERIOD', 'SELLER_METRICS_DELAY_RATE',\n",
       "       'SELLER_METRICS_DELAY_VALUE', 'SELLER_METRICS_DELAY_PERIOD',\n",
       "       'SELLER_METRICS_SALES_PERIOD', 'SELLER_METRICS_SALES_COMPLETED',\n",
       "       'SELLER_METRICS_CANCELLATIONS_PERIOD',\n",
       "       'SELLER_METRICS_CANCELLATIONS_RATE',\n",
       "       'SELLER_METRICS_CANCELLATIONS_VALUE', 'SELLER_LEVEL_ID',\n",
       "       'SHIPPING_FREE', 'SHIPPING_LOGISTIC_TYPE', 'SHIPPING_PICK_UP',\n",
       "       'ADRESS_STATE_ID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printea la columnas del dataset\n",
    "products.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-09T23:49:05.788278Z",
     "start_time": "2021-03-09T23:49:05.710669Z"
    },
    "hidden": true
   },
   "source": [
    "Se puede ver claramente que se encuentran los siguientes tipos de variables:\n",
    "    \n",
    "1. Tipo `ITEM`: Variables asociadas al ítem.\n",
    "\n",
    "\n",
    "2. Tipo `SELLER`: Variables asociadas al vendedor.\n",
    "\n",
    "\n",
    "3. Tipo `SHIPPING`: Variables asociadas al envío.\n",
    "\n",
    "\n",
    "4. Tipo `ADRESS`: Variable que indica el departamento donde se encuentra el ítem.\n",
    "\n",
    "\n",
    "5. Tipo `SEARCH`: Variables asociadas a la búsqueda: categoría y offset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Transformación de los Datos\n",
    "\n",
    "En esta subsección se arreglan, limpian y transforman el dataset de productos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T15:46:39.812860Z",
     "start_time": "2021-03-16T15:46:39.804852Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Arreglo a la ADRESS_STATE_ID: para algunos productos el ADRESS_STATE_ID hay que arreglar su dato\n",
    "# Se uso el ITEM_PERMALINK para entender cual era el verdadero dato de ADRESS_STATE_ID\n",
    "cambios_de_direccion = {\n",
    "                        'TUNPUEJPR1gxMDljZA': 'CO-DC', \n",
    "                        'TUNPUEFOVGFiZWI3': 'CO-ANT ',\n",
    "                        'TUNPUENVTmE3NmQ4': 'CO-CUN',\n",
    "                        'TUNPUFZBTGExNmNjNg': 'CO-VAC',\n",
    "                        'TUNPUFJJU2ExMWIyYg': 'CO-RIS',\n",
    "                        'TUNPUEFUTG9mNDk5': 'CO-ATL',\n",
    "                        'TUNPUFRPTGExNGZkNA': 'CO-TOL',\n",
    "                        'TUNPUFNBTnJlMjMw': 'CO-SAN',\n",
    "                        'TUNPUEJPTHI1Mzlk': 'CO-BOL',\n",
    "                        'TUNPUE1BR2FiZjQ0': 'CO-MAG',\n",
    "                        'TUNPUENBTHNjODY4': 'CO-CAL',\n",
    "                        'TUNPUE1FVGExNzFjNQ': 'CO-MET',\n",
    "                        'TUNPUFFVSW9kYmZm': 'CO-QUI',\n",
    "                        'TUNPUE5PUnIxNDkyZg': 'CO-NSA', \n",
    "                        'TUNPUEFSQ2E4Zjc3': 'CO-SAP',\n",
    "                        'TUNPUEJPWWE4YzMz': 'CO-BOY',\n",
    "                        'TUNPUENBVWExM2Q1NQ': 'CO-CAU',\n",
    "                        'TUNPUENPUmFkZGIw': 'CO-COR',\n",
    "                        'TUNPUEdVQWExOTYx': 'CO-LAG',\n",
    "                        'TUNPUE5BUm8xYzk4': 'CO-NAR', \n",
    "                        'TUNPUFNVQ2U4ZWQ0': 'CO-SUC',\n",
    "                        'TUNPUENBU2U2OWIy': 'CO-CAS',\n",
    "                        'TUNPUENFU3IxODA4Mg': 'CO-CES',\n",
    "                        'TUNPUEFNQXMxMzQ2YQ': 'CO-AMA'\n",
    "                       }\n",
    "\n",
    "# Arregla un error que se detecto en las direcciones\n",
    "products.loc[products['ADRESS_STATE_ID'].isin(cambios_de_direccion.keys()), 'ADRESS_STATE_ID'] = \\\n",
    "products.loc[products['ADRESS_STATE_ID'].isin(cambios_de_direccion.keys()), 'ADRESS_STATE_ID'].map(cambios_de_direccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T15:46:39.834528Z",
     "start_time": "2021-03-16T15:46:39.814803Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Ajuste a la condicion del item\n",
    "\n",
    "# Se cambia nan por not_specified\n",
    "products.loc[products['ITEM_CONDITION'].isna(), 'ITEM_CONDITION'] = 'not_specified'\n",
    "\n",
    "# Ajustes al precio \n",
    "\n",
    "# Se quitan productos que no tienen precio (generalmente precio a convenir)\n",
    "# Es decir este analisis aplica para productos con precio fijo\n",
    "products = products.loc[~products['ITEM_PRICE'].isna()]\n",
    "products.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Se encontro en google la tasa de cambio de dolar a cop el dia 7 de marzo (cuando se descargaron los datos)\n",
    "exchange_rate_usd_to_cop = 3142.99 \n",
    "products.loc[products['ITEM_CURRENCY_ID'] == 'USD', 'ITEM_PRICE'] *= exchange_rate_usd_to_cop\n",
    "products.loc[products['ITEM_CURRENCY_ID'] == 'USD', 'ITEM_CURRENCY_ID'] = 'COP'\n",
    "\n",
    "# Cambia ITEM_ORIGINAL_PRICE por el ITEM_PRICE como se indica en el documento\n",
    "products.loc[products['ITEM_ORIGINAL_PRICE'].isna(), 'ITEM_ORIGINAL_PRICE'] = \\\n",
    "products.loc[products['ITEM_ORIGINAL_PRICE'].isna(), 'ITEM_PRICE']\n",
    "\n",
    "# Crea las variables de descuento absoluto y la tasa\n",
    "products['ITEM_DISCOUNT_VALUE'] = products['ITEM_ORIGINAL_PRICE'] - products['ITEM_PRICE']\n",
    "products['ITEM_DISCOUNT_RATE'] = products['ITEM_DISCOUNT_VALUE']/products['ITEM_ORIGINAL_PRICE']\n",
    "\n",
    "# Crea la variable de venta total: This is an approximation\n",
    "products['ITEM_SELL_TOTAL'] = products['ITEM_PRICE']*products['ITEM_SOLD_QUANTITY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T15:46:39.871382Z",
     "start_time": "2021-03-16T15:46:39.836004Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Ajuste a variables del vendedor\n",
    "\n",
    "# Cambio de nan to not_specified para SELLER_STATUS\n",
    "products.loc[products['SELLER_STATUS'].isna(), 'SELLER_STATUS'] = 'not_specified'\n",
    "products.loc[products['SELLER_LEVEL_ID'].isna(), 'SELLER_LEVEL_ID'] = 'not_specified'\n",
    "\n",
    "# Cambio nan to 0 para SELLER_METRICS_SALES_PERIOD\n",
    "products.loc[products['SELLER_METRICS_SALES_PERIOD'].isna(), 'SELLER_METRICS_SALES_COMPLETED'] = 0\n",
    "products.loc[products['SELLER_METRICS_SALES_PERIOD'].isna(), 'SELLER_METRICS_SALES_PERIOD'] = '60 days'\n",
    "products.loc[products['SELLER_METRICS_SALES_PERIOD'] == '60 months', 'SELLER_METRICS_SALES_COMPLETED'] *= (60/(30*60))\n",
    "products.loc[products['SELLER_METRICS_SALES_PERIOD'] == '3 months', 'SELLER_METRICS_SALES_COMPLETED'] *= (60/90)\n",
    "products.loc[products['SELLER_METRICS_SALES_PERIOD'] == '365 days', 'SELLER_METRICS_SALES_COMPLETED'] *= (60/365)\n",
    "products['SELLER_METRICS_SALES_PERIOD'] = '60 days'\n",
    "\n",
    "# Estandarizacion de las metricas absolutas del vendedor (por periodo de tiempo)\n",
    "\n",
    "# Cancelaciones \n",
    "products.loc[products['SELLER_METRICS_CANCELLATIONS_PERIOD'] == '60 months', 'SELLER_METRICS_CANCELLATIONS_VALUE'] *= (60/(30*60))\n",
    "products.loc[products['SELLER_METRICS_CANCELLATIONS_PERIOD'] == '3 months', 'SELLER_METRICS_CANCELLATIONS_VALUE'] *= (60/90)\n",
    "products.loc[products['SELLER_METRICS_CANCELLATIONS_PERIOD'] == '365 days', 'SELLER_METRICS_CANCELLATIONS_VALUE'] *= (60/365)\n",
    "products['SELLER_METRICS_CANCELLATIONS_PERIOD'] = '60 days'\n",
    "\n",
    "# Quejas \n",
    "products.loc[products['SELLER_METRICS_CLAIMS_PERIOD'] == '60 months', 'SELLER_METRICS_CLAIMS_VALUE'] *= (60/(30*60))\n",
    "products.loc[products['SELLER_METRICS_CLAIMS_PERIOD'] == '3 months', 'SELLER_METRICS_CLAIMS_VALUE'] *= (60/90)\n",
    "products.loc[products['SELLER_METRICS_CLAIMS_PERIOD'] == '365 days', 'SELLER_METRICS_CLAIMS_VALUE'] *= (60/365)\n",
    "products['SELLER_METRICS_CLAIMS_PERIOD'] = '60 days'\n",
    "\n",
    "# Demoras \n",
    "products.loc[products['SELLER_METRICS_DELAY_PERIOD'] == '60 months', 'SELLER_METRICS_DELAY_VALUE'] *= (60/(30*60))\n",
    "products.loc[products['SELLER_METRICS_DELAY_PERIOD'] == '3 months', 'SELLER_METRICS_DELAY_VALUE'] *= (60/90)\n",
    "products.loc[products['SELLER_METRICS_DELAY_PERIOD'] == '365 days', 'SELLER_METRICS_DELAY_VALUE'] *= (60/365)\n",
    "products['SELLER_METRICS_DELAY_PERIOD'] = '60 days'\n",
    "\n",
    "## Ajustes a variables del shipping/envio\n",
    "\n",
    "# Cambio de nan to not_specified para SHIPPING_LOGISTIC_TYPE\n",
    "products.loc[products['SHIPPING_LOGISTIC_TYPE'].isna(), 'SHIPPING_LOGISTIC_TYPE'] = 'not_specified'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T15:46:39.894590Z",
     "start_time": "2021-03-16T15:46:39.872905Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAS DIMENSIONES DE LA BASE DE PRODUCTOS SON: (13043, 53)\n"
     ]
    }
   ],
   "source": [
    "# Encuentra las categorias cuyas cantidades vendidas son 0 y las remueve\n",
    "sold_quantity_per_category = products.groupby('SEARCH_CATEGORY_ID')['ITEM_SELL_TOTAL'].sum().sort_values(ascending=False)\n",
    "categories_zero_sold_quantity = sold_quantity_per_category.loc[sold_quantity_per_category == 0].index.tolist()\n",
    "products = products.loc[~products['SEARCH_CATEGORY_ID'].isin(categories_zero_sold_quantity)]\n",
    "\n",
    "# Se remueven los productos cuya cantidad vendida es de 5000\n",
    "products = products.loc[products['ITEM_SOLD_QUANTITY'] < 5000]\n",
    "products = products.loc[~products['ITEM_DOMAIN_ID'].isna()]\n",
    "\n",
    "# Imprime las dimensiones del dataset de products final\n",
    "print('LAS DIMENSIONES DE LA BASE DE PRODUCTOS SON: {}'.format(products.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Selección de Predictores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T15:46:39.902013Z",
     "start_time": "2021-03-16T15:46:39.896185Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAS DIMENSIONES DE LA DATA DE PRODUCTOS SON: (13043, 30)\n"
     ]
    }
   ],
   "source": [
    "# Variables de item y search  \n",
    "item_vars = [\n",
    "    'ITEM_PRICE',\n",
    "    'ITEM_AVAILABLE_QUANTITY',\n",
    "    'ITEM_SOLD_QUANTITY', # Variable de respuesta\n",
    "    'ITEM_LISTING_TYPE_ID',\n",
    "    'ITEM_CONDITION',\n",
    "    'ITEM_DOMAIN_ID',\n",
    "    'ITEM_ACCEPTS_MERCADOPAGO',\n",
    "    'ITEM_ORIGINAL_PRICE',\n",
    "    'ITEM_USE_THUMBNAIL_ID',\n",
    "    'SEARCH_CATEGORY_ID', # La categoria del busqueda del item \n",
    "    'SEARCH_OFFSET', # El offset de busqueda que en el que se obtuvo el item\n",
    "#     'ITEM_DISCOUNT_VALUE', # Se omite ya que es una combinacion lineal de ITEM_PRICE y ITEM_ORIGINAL_PRICE\n",
    "    'ITEM_DISCOUNT_RATE',\n",
    "]\n",
    "\n",
    "# Variables del seller y el shipping\n",
    "seller_vars = [\n",
    "    'SELLER_REP_TRANSACTIONS_TOTAL',\n",
    "    'SELLER_REP_TRANSACTIONS_CANCELED',\n",
    "    'SELLER_REP_RATING_NEG',\n",
    "    'SELLER_REP_RATING_POS',\n",
    "    'SELLER_REP_RATING_NEU',\n",
    "    'SELLER_TRANSACTIONS_COMPLETED',\n",
    "    'SELLER_METRICS_CLAIMS_RATE',\n",
    "    'SELLER_METRICS_CLAIMS_VALUE',\n",
    "    'SELLER_METRICS_DELAY_RATE',\n",
    "    'SELLER_METRICS_DELAY_VALUE', \n",
    "    'SELLER_METRICS_SALES_COMPLETED',\n",
    "    'SELLER_METRICS_CANCELLATIONS_RATE',\n",
    "    'SELLER_METRICS_CANCELLATIONS_VALUE', \n",
    "    'SELLER_LEVEL_ID',\n",
    "    'SHIPPING_FREE',\n",
    "    'SHIPPING_LOGISTIC_TYPE', \n",
    "    'SHIPPING_PICK_UP',\n",
    "    'ADRESS_STATE_ID', \n",
    "]\n",
    "\n",
    "# Seleeciona unicamente columnas anteriormente definidas\n",
    "products_selected = products[item_vars + seller_vars]\n",
    "products_selected.reset_index(drop=True, inplace=True)\n",
    "print('LAS DIMENSIONES DE LA DATA DE PRODUCTOS SON: {}'.format(products_selected.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estandarización, OneHotEncoding y Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T15:46:39.913505Z",
     "start_time": "2021-03-16T15:46:39.903726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAS DIMENSIONES DE LA DATA NUMERICA DE PRODUCTOS SON: (13043, 19)\n",
      "LAS DIMENSIONES DE LA DATA CATEGORICA DE PRODUCTOS SON: (13043, 7)\n",
      "LAS DIMENSIONES DE LA DATA BINARIA DE PRODUCTOS SON: (13043, 4)\n"
     ]
    }
   ],
   "source": [
    "# Crea un dataframe de variables numericas y otro de categoricas\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "products_numeric = products_selected.select_dtypes(include=numerics)\n",
    "\n",
    "categorical = ['object']\n",
    "products_categorical = products_selected.select_dtypes(include=categorical)\n",
    "\n",
    "# Cambia las variables \n",
    "binary = ['bool']\n",
    "products_binary = products_selected.select_dtypes(include=binary)\n",
    "\n",
    "# Revisa que todas las variables de products_selected esten en products_numeric, products_binary y products_categorical\n",
    "assert(products_selected.shape[1] == (products_categorical.shape[1]+products_numeric.shape[1]+products_binary.shape[1]))\n",
    "\n",
    "# Imprime las dimensiones de cada base\n",
    "print('LAS DIMENSIONES DE LA DATA NUMERICA DE PRODUCTOS SON: {}'.format(products_numeric.shape))\n",
    "print('LAS DIMENSIONES DE LA DATA CATEGORICA DE PRODUCTOS SON: {}'.format(products_categorical.shape))\n",
    "print('LAS DIMENSIONES DE LA DATA BINARIA DE PRODUCTOS SON: {}'.format(products_binary.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T15:46:39.968567Z",
     "start_time": "2021-03-16T15:46:39.915043Z"
    }
   },
   "outputs": [],
   "source": [
    "## Cambio a 1-0 para las binarias\n",
    "# Cambia las variables binarias True-False por 1-0 \n",
    "products_binary = products_binary.astype(int)\n",
    "\n",
    "## OneHotEncoding para las columnas categoricas\n",
    "# Define el one_hot_encoder\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "# Transforma los datos\n",
    "products_encoded_categoricals = one_hot_encoder.fit_transform(products_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T15:46:40.131028Z",
     "start_time": "2021-03-16T15:46:39.970161Z"
    }
   },
   "outputs": [],
   "source": [
    "# Divide los datos en entrenamiento y prueba\n",
    "Y = products_numeric['ITEM_SOLD_QUANTITY']\n",
    "X = products_numeric.drop(columns='ITEM_SOLD_QUANTITY')\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.3, random_state=1608)\n",
    "indexes_train = X_train.index.tolist()\n",
    "indexes_test = X_test.index.tolist()\n",
    "\n",
    "## Estandarizacion para las numericas\n",
    "standard_scaler = StandardScaler() \n",
    "X_train_std = standard_scaler.fit_transform(X_train)\n",
    "X_test_std = standard_scaler.transform(X_test)\n",
    "\n",
    "## Construye la matriz de datos con todos los tipos de data\n",
    "X_train_total = np.concatenate((X_train_std, products_encoded_categoricals[indexes_train,:],\n",
    "                                products_binary.loc[indexes_train]), axis=1)\n",
    "X_test_total = np.concatenate((X_test_std, products_encoded_categoricals[indexes_test,:],\n",
    "                                products_binary.loc[indexes_test]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T15:48:15.336991Z",
     "start_time": "2021-03-16T15:48:15.327715Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ITEM_SOLD_QUANTITY</th>\n",
       "      <th>COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>1460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>1300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250</td>\n",
       "      <td>1163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>1058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>150</td>\n",
       "      <td>554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200</td>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ITEM_SOLD_QUANTITY  COUNT\n",
       "0                  500   1460\n",
       "1                    5   1413\n",
       "2                   50   1300\n",
       "3                  250   1163\n",
       "4                   25   1058\n",
       "5                  100    778\n",
       "6                  150    554\n",
       "7                  200    426\n",
       "8                    0    361\n",
       "9                    1    211\n",
       "10                   3    148\n",
       "11                   4    122\n",
       "12                   2    117\n",
       "13                   9      3\n",
       "14                  12      2\n",
       "15                  14      2\n",
       "16                  15      2\n",
       "17                  59      1\n",
       "18                   8      1\n",
       "19                  35      1\n",
       "20                  10      1\n",
       "21                  13      1\n",
       "22                  21      1\n",
       "23                   6      1\n",
       "24                  23      1\n",
       "25                  31      1\n",
       "26                  55      1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conteo de valores para la respuesta\n",
    "Y_train.value_counts().reset_index().rename(columns={'index': 'ITEM_SOLD_QUANTITY',\n",
    "                                                     'ITEM_SOLD_QUANTITY': 'COUNT'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es claro que algunos valores son muy escasos y hay otros que se encuentran mucho más presentes en los ítems tomados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de Predicción - Sold Quantity\n",
    "\n",
    "En esta sección se construye y evalua el rendimiento de disintos modelos de Machine Learning para estimar la cantidad vendida de un ítem en función de las variables escogidas previamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost (Gradient Boosting Trees)\n",
    "\n",
    "Uno de los algoritmos que escogí para usar es Gradient Boosting Trees a través del framework `XGBoost` conocido por su excelente rendimiento y rapidez. Lo que se hara es buscar los mejores hiper-parámetros por validación cruzada y evaluar el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:18:29.993849Z",
     "start_time": "2021-03-15T23:13:40.443215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  4.7min finished\n"
     ]
    }
   ],
   "source": [
    "# Parametros del XGBoost para tunear (se escogio el dart booster para evitar el overfitting)\n",
    "param_tuning = {\n",
    "        'learning_rate': [0.25],\n",
    "        'max_depth': [5, 7],\n",
    "        'min_child_weight': [3, 5],\n",
    "        'subsample': [1.0],\n",
    "        'colsample_bytree': [0.50],\n",
    "        'n_estimators' : [100],\n",
    "        'objective': ['reg:squarederror'],\n",
    "        'booster': ['dart'],\n",
    "        'rate_drop': [0.1, 0.25],\n",
    "        'skip_drop': [0.1, 0.5]\n",
    "    }\n",
    "\n",
    "# Se evalua para todas las combinaciones de hiperparametros cual tiene el menor error de validacion\n",
    "# usando validacion cruzada para 5-folds\n",
    "\n",
    "# Modelo XGBRegressor\n",
    "xgb_model = XGBRegressor()\n",
    "\n",
    "# Validacion cruzada\n",
    "k_folds = KFold(n_splits=5, shuffle=True, random_state=1608)\n",
    "grid_search_cv = GridSearchCV(estimator = xgb_model,\n",
    "                              param_grid = param_tuning,            \n",
    "                              cv = k_folds,\n",
    "                              n_jobs = -1,\n",
    "                              verbose = 1)\n",
    "cv_fit = grid_search_cv.fit(X=X_train_total, y=Y_train) # Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:18:35.962717Z",
     "start_time": "2021-03-15T23:18:35.951548Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'booster': 'dart',\n",
       " 'colsample_bytree': 0.5,\n",
       " 'learning_rate': 0.25,\n",
       " 'max_depth': 7,\n",
       " 'min_child_weight': 5,\n",
       " 'n_estimators': 100,\n",
       " 'objective': 'reg:squarederror',\n",
       " 'rate_drop': 0.1,\n",
       " 'skip_drop': 0.5,\n",
       " 'subsample': 1.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprime los mejores parametros bajo el score de cv calculado para cada iteracion\n",
    "grid_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:18:42.759622Z",
     "start_time": "2021-03-15T23:18:42.622228Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se generan las predicciones para el entrenamiento y prueba y se evaluan dos metricas: RMSE y MAE\n",
    "xgb_best_model = grid_search_cv.best_estimator_\n",
    "test_predictions = xgb_best_model.predict(X_test_total)\n",
    "train_predictions = xgb_best_model.predict(X_train_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:18:43.307340Z",
     "start_time": "2021-03-15T23:18:43.296398Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE DE ENTRENAMIENTO: 79.35\n",
      "RMSE DE PRUEBA: 104.87\n",
      "DIFERENCIA DE: 32.17%\n"
     ]
    }
   ],
   "source": [
    "# Comparacion RSME train y test\n",
    "rmse_train = np.sqrt(mean_squared_error(y_pred=train_predictions, y_true=Y_train))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_pred=test_predictions, y_true=Y_test))\n",
    "print('RMSE DE ENTRENAMIENTO: {}'.format(np.round(rmse_train,2)))\n",
    "print('RMSE DE PRUEBA: {}'.format(np.round(rmse_test,2)))\n",
    "diferencia_porcentual = np.round(100*(rmse_test-rmse_train)/rmse_train,2)\n",
    "print('DIFERENCIA DE: {}%'.format(diferencia_porcentual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:18:44.856631Z",
     "start_time": "2021-03-15T23:18:44.851789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE DE ENTRENAMIENTO: 54.74\n",
      "MAE DE PRUEBA: 72.84\n",
      "DIFERENCIA DE: 33.07%\n"
     ]
    }
   ],
   "source": [
    "# Comparacion MAE train y test\n",
    "mae_train = mean_absolute_error(y_pred=train_predictions, y_true=Y_train)\n",
    "mae_test = mean_absolute_error(y_pred=test_predictions, y_true=Y_test)\n",
    "diferencia_porcentual = np.round(100*(mae_test-mae_train)/mae_train,2)\n",
    "print('MAE DE ENTRENAMIENTO: {}'.format(np.round(mae_train,2)))\n",
    "print('MAE DE PRUEBA: {}'.format(np.round(mae_test,2)))\n",
    "print('DIFERENCIA DE: {}%'.format(diferencia_porcentual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:18:46.508546Z",
     "start_time": "2021-03-15T23:18:46.404184Z"
    }
   },
   "outputs": [],
   "source": [
    "values = sorted(Y_train.unique())\n",
    "test_predictions = [find_nearest(values, p)for p in test_predictions] \n",
    "train_predictions = [find_nearest(values, p)for p in train_predictions] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:18:48.884867Z",
     "start_time": "2021-03-15T23:18:48.878494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE DE ENTRENAMIENTO: 86.3\n",
      "RMSE DE PRUEBA: 111.63\n",
      "DIFERENCIA DE: 29.35%\n"
     ]
    }
   ],
   "source": [
    "# Comparacion RSME train y test\n",
    "rmse_train = np.sqrt(mean_squared_error(y_pred=train_predictions, y_true=Y_train))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_pred=test_predictions, y_true=Y_test))\n",
    "print('RMSE DE ENTRENAMIENTO: {}'.format(np.round(rmse_train,2)))\n",
    "print('RMSE DE PRUEBA: {}'.format(np.round(rmse_test,2)))\n",
    "diferencia_porcentual = np.round(100*(rmse_test-rmse_train)/rmse_train,2)\n",
    "print('DIFERENCIA DE: {}%'.format(diferencia_porcentual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:18:50.188408Z",
     "start_time": "2021-03-15T23:18:50.182247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE DE ENTRENAMIENTO: 49.49\n",
      "MAE DE PRUEBA: 69.39\n",
      "DIFERENCIA DE: 40.21%\n"
     ]
    }
   ],
   "source": [
    "# Comparacion MAE train y test\n",
    "mae_train = mean_absolute_error(y_pred=train_predictions, y_true=Y_train)\n",
    "mae_test = mean_absolute_error(y_pred=test_predictions, y_true=Y_test)\n",
    "diferencia_porcentual = np.round(100*(mae_test-mae_train)/mae_train,2)\n",
    "print('MAE DE ENTRENAMIENTO: {}'.format(np.round(mae_train,2)))\n",
    "print('MAE DE PRUEBA: {}'.format(np.round(mae_test,2)))\n",
    "print('DIFERENCIA DE: {}%'.format(diferencia_porcentual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:18:52.352508Z",
     "start_time": "2021-03-15T23:18:52.322098Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se crea un dataframe con los resultados\n",
    "resultados_train = pd.DataFrame({'TYPE': ['TRAIN']*len(Y_train), 'TRUE': Y_train, 'PREDICTED': train_predictions})\n",
    "resultados_test = pd.DataFrame({'TYPE': ['TEST']*len(Y_test), 'TRUE': Y_test, 'PREDICTED': test_predictions})\n",
    "resultados_xgb = pd.concat([resultados_train, resultados_test], axis=0).reset_index(drop=True)\n",
    "resultados_xgb['ABSOLUTE_ERROR'] = (resultados_xgb['TRUE']-resultados_xgb['PREDICTED']).abs()\n",
    "resultados_xgb['SQUARE_ERROR'] = (resultados_xgb['TRUE']-resultados_xgb['PREDICTED'])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:18:53.113879Z",
     "start_time": "2021-03-15T23:18:53.085969Z"
    }
   },
   "outputs": [],
   "source": [
    "# Resultados por cantidad\n",
    "resultados_por_cantidad = resultados_xgb.groupby(['TYPE', 'TRUE'])[['ABSOLUTE_ERROR', 'SQUARE_ERROR']].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:18:53.860525Z",
     "start_time": "2021-03-15T23:18:53.837855Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TYPE</th>\n",
       "      <th>TRUE</th>\n",
       "      <th>ABSOLUTE_ERROR</th>\n",
       "      <th>SQUARE_ERROR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST</td>\n",
       "      <td>0</td>\n",
       "      <td>13.389937</td>\n",
       "      <td>509.805031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST</td>\n",
       "      <td>1</td>\n",
       "      <td>14.776119</td>\n",
       "      <td>718.059701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST</td>\n",
       "      <td>2</td>\n",
       "      <td>11.974026</td>\n",
       "      <td>381.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST</td>\n",
       "      <td>3</td>\n",
       "      <td>18.562500</td>\n",
       "      <td>864.020833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST</td>\n",
       "      <td>4</td>\n",
       "      <td>15.784615</td>\n",
       "      <td>673.815385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TEST</td>\n",
       "      <td>5</td>\n",
       "      <td>38.708943</td>\n",
       "      <td>3173.508943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TEST</td>\n",
       "      <td>6</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>5386.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TEST</td>\n",
       "      <td>7</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>2704.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TEST</td>\n",
       "      <td>8</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>64.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TEST</td>\n",
       "      <td>14</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>121.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TEST</td>\n",
       "      <td>25</td>\n",
       "      <td>54.049107</td>\n",
       "      <td>5547.450893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TEST</td>\n",
       "      <td>50</td>\n",
       "      <td>63.566004</td>\n",
       "      <td>7161.996383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TEST</td>\n",
       "      <td>56</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>1936.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TEST</td>\n",
       "      <td>100</td>\n",
       "      <td>66.703170</td>\n",
       "      <td>8505.406340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TEST</td>\n",
       "      <td>150</td>\n",
       "      <td>61.799127</td>\n",
       "      <td>6986.052402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TEST</td>\n",
       "      <td>200</td>\n",
       "      <td>62.897436</td>\n",
       "      <td>7059.512821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TEST</td>\n",
       "      <td>250</td>\n",
       "      <td>64.666667</td>\n",
       "      <td>11286.886406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TEST</td>\n",
       "      <td>500</td>\n",
       "      <td>165.544554</td>\n",
       "      <td>46850.049505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TYPE  TRUE  ABSOLUTE_ERROR  SQUARE_ERROR\n",
       "0   TEST     0       13.389937    509.805031\n",
       "1   TEST     1       14.776119    718.059701\n",
       "2   TEST     2       11.974026    381.818182\n",
       "3   TEST     3       18.562500    864.020833\n",
       "4   TEST     4       15.784615    673.815385\n",
       "5   TEST     5       38.708943   3173.508943\n",
       "6   TEST     6       69.000000   5386.000000\n",
       "7   TEST     7       52.000000   2704.000000\n",
       "8   TEST     8        8.000000     64.000000\n",
       "9   TEST    14       11.000000    121.000000\n",
       "10  TEST    25       54.049107   5547.450893\n",
       "11  TEST    50       63.566004   7161.996383\n",
       "12  TEST    56       44.000000   1936.000000\n",
       "13  TEST   100       66.703170   8505.406340\n",
       "14  TEST   150       61.799127   6986.052402\n",
       "15  TEST   200       62.897436   7059.512821\n",
       "16  TEST   250       64.666667  11286.886406\n",
       "17  TEST   500      165.544554  46850.049505"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprime los resultados por cantidad en cuanto al MAE y MSE para los datos de prueba\n",
    "resultados_por_cantidad.loc[resultados_por_cantidad['TYPE']=='TEST']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análisis de Resultados y Rendimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de escoger algunos de los hiper-parámetros del algoritmo de `XGBoost` por validación cruzada, se usa el modelo para mirar como predice tanto en el entrenamiento como en la prueba y los resultados de manera general son:\n",
    "\n",
    "* Métricas del modelo:\n",
    "    |       | RMSE | MAE   |\n",
    "    | :---        |    ----:   |          ---: |\n",
    "    | ENTRENAMIENTO      |    79.35    |   54.74     |\n",
    "    | PRUEBA   |    104.87      |   72.84    |\n",
    "    | DIFERENCIA PORCENTUAL   |    32.17%      |   33.07%    |\n",
    "    \n",
    "    Se puede que realmente hay un overfitting que a pesar de no ser tan grande sí es un poco considerable. El error promedio (mírese el RMSE and MAE) es realmente alto, por ejemplo, en promedio se tiene un MAE de 72.84 unidades vendidas! Una vez ví estos resultados y dándole un poco de sentido al problema, me dí cuenta de lo difícil que es resolver este problema por la variedad de ítems y de variables de estos que se presentan en el marketplace.\n",
    "\n",
    "    Una especie de __round__ de las predicciones: Sabiendo que `ITEM_SOLD_QUANTITY` realmente es una variable de rangos como se explica [aquí](https://developers.mercadolibre.com.ar/en_us/items-and-searches) se propone una hacer una aproximación a cada predicción al valor más cercano de los posibles que se registraron en la muestra tomada. Después de hacer esto, los resultados mejoraron un poco: \n",
    "    \n",
    "    |       | RMSE | MAE   |\n",
    "    | :---        |    ----:   |          ---: |\n",
    "    | ENTRENAMIENTO      |    86.30    |   49.49     |\n",
    "    | PRUEBA   |    111.63      |   69.39    |\n",
    "    | DIFERENCIA PORCENTUAL   |    29.35%      |   40.21%    |\n",
    "    * con aproximación\n",
    "    \n",
    "    De manera general el MAE bajo (aunque con la diferencia porcentual el overfitting subió un poco) y el RMSE subió (aunque con la diferencia porcentual el overfitting bajó un poco).\n",
    "    \n",
    "\n",
    "* Si miramos los errores para cada cantidad vendida en los valores reales se puede ver que para las cantidades más pequeñas hay un error menor, mientras que para las más grandes el error sube considerablemente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NNs (Redes Neuronales)\n",
    "\n",
    "Uno de los algoritmos que escogí para usar es Redes Neuronales utilizando `Tensorflow` y en particular el modelo de `Keras` dentro de este. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:20:05.788285Z",
     "start_time": "2021-03-15T23:20:05.726151Z"
    }
   },
   "outputs": [],
   "source": [
    "# Semilla aleatoria fijada \n",
    "tf.random.set_seed(200)\n",
    "\n",
    "# Capa General 1: Capa Convolucional\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Capa de 10 neuronas con activacion relu y dropout de 0.25\n",
    "nn_model.add(tf.keras.layers.Dense(10, input_shape=(X_train_total.shape[1],), activation='relu'))\n",
    "nn_model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "# Capa de 25 neuronas con activacion relu y dropout de 0.25\n",
    "nn_model.add(tf.keras.layers.Dense(25, activation='relu'))\n",
    "nn_model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "# Capa de 25 neuronas con activacion relu y dropout de 0.5\n",
    "nn_model.add(tf.keras.layers.Dense(25, activation='relu'))\n",
    "nn_model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "# Capa de 25 neuronas con activacion relu y dropout de 0.25\n",
    "nn_model.add(tf.keras.layers.Dense(25, activation='relu'))\n",
    "nn_model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "# Capa de 10 neuronas con activacion relu y dropout de 0.25\n",
    "nn_model.add(tf.keras.layers.Dense(10, activation='relu'))\n",
    "nn_model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "# Capa de output \n",
    "nn_model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "# Se especifica cual es el optimizador (metodo de descenso del gradiente a usar, la función de perdida y las metricas a mostrar)\n",
    "nn_model.compile(optimizer='adam',loss=tf.keras.losses.MeanSquaredError(), metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:20:06.189531Z",
     "start_time": "2021-03-15T23:20:06.185049Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 10)                11650     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 25)                275       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                260       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 13,496\n",
      "Trainable params: 13,496\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Printea la arquitectura de la red\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:20:22.226758Z",
     "start_time": "2021-03-15T23:20:06.681780Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbc341958b0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se hace el fit (detras un metodo de gradiente)\n",
    "nn_model.fit(X_train_total, Y_train, epochs=250, batch_size=2000, verbose=0, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:20:28.920481Z",
     "start_time": "2021-03-15T23:20:28.652688Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se generan las predicciones para el entrenamiento y prueba y se evaluan dos metricas: RMSE y MAE\n",
    "test_predictions = nn_model.predict(X_test_total)\n",
    "train_predictions = nn_model.predict(X_train_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:20:29.016300Z",
     "start_time": "2021-03-15T23:20:29.010840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE DE ENTRENAMIENTO: 101.38\n",
      "RMSE DE PRUEBA: 112.71\n",
      "DIFERENCIA DE: 11.17%\n"
     ]
    }
   ],
   "source": [
    "# Comparacion RSME train y test\n",
    "rmse_train = np.sqrt(mean_squared_error(y_pred=train_predictions, y_true=Y_train))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_pred=test_predictions, y_true=Y_test))\n",
    "print('RMSE DE ENTRENAMIENTO: {}'.format(np.round(rmse_train,2)))\n",
    "print('RMSE DE PRUEBA: {}'.format(np.round(rmse_test,2)))\n",
    "diferencia_porcentual = np.round(100*(rmse_test-rmse_train)/rmse_train,2)\n",
    "print('DIFERENCIA DE: {}%'.format(diferencia_porcentual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:20:30.412944Z",
     "start_time": "2021-03-15T23:20:30.407832Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE DE ENTRENAMIENTO: 67.57\n",
      "MAE DE PRUEBA: 75.05\n",
      "DIFERENCIA DE: 11.07%\n"
     ]
    }
   ],
   "source": [
    "# Comparacion MAE train y test\n",
    "mae_train = mean_absolute_error(y_pred=train_predictions, y_true=Y_train)\n",
    "mae_test = mean_absolute_error(y_pred=test_predictions, y_true=Y_test)\n",
    "diferencia_porcentual = np.round(100*(mae_test-mae_train)/mae_train,2)\n",
    "print('MAE DE ENTRENAMIENTO: {}'.format(np.round(mae_train,2)))\n",
    "print('MAE DE PRUEBA: {}'.format(np.round(mae_test,2)))\n",
    "print('DIFERENCIA DE: {}%'.format(diferencia_porcentual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:20:33.182880Z",
     "start_time": "2021-03-15T23:20:33.071399Z"
    }
   },
   "outputs": [],
   "source": [
    "values = sorted(Y_train.unique())\n",
    "test_predictions = [find_nearest(values, p)for p in test_predictions] \n",
    "train_predictions = [find_nearest(values, p)for p in train_predictions] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:20:34.273213Z",
     "start_time": "2021-03-15T23:20:34.266940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE DE ENTRENAMIENTO: 110.47\n",
      "RMSE DE PRUEBA: 118.93\n",
      "DIFERENCIA DE: 7.66%\n"
     ]
    }
   ],
   "source": [
    "# Comparacion RSME train y test\n",
    "rmse_train = np.sqrt(mean_squared_error(y_pred=train_predictions, y_true=Y_train))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_pred=test_predictions, y_true=Y_test))\n",
    "print('RMSE DE ENTRENAMIENTO: {}'.format(np.round(rmse_train,2)))\n",
    "print('RMSE DE PRUEBA: {}'.format(np.round(rmse_test,2)))\n",
    "diferencia_porcentual = np.round(100*(rmse_test-rmse_train)/rmse_train,2)\n",
    "print('DIFERENCIA DE: {}%'.format(diferencia_porcentual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:20:35.263598Z",
     "start_time": "2021-03-15T23:20:35.257471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE DE ENTRENAMIENTO: 68.29\n",
      "MAE DE PRUEBA: 74.07\n",
      "DIFERENCIA DE: 8.47%\n"
     ]
    }
   ],
   "source": [
    "# Comparacion MAE train y test\n",
    "mae_train = mean_absolute_error(y_pred=train_predictions, y_true=Y_train)\n",
    "mae_test = mean_absolute_error(y_pred=test_predictions, y_true=Y_test)\n",
    "diferencia_porcentual = np.round(100*(mae_test-mae_train)/mae_train,2)\n",
    "print('MAE DE ENTRENAMIENTO: {}'.format(np.round(mae_train,2)))\n",
    "print('MAE DE PRUEBA: {}'.format(np.round(mae_test,2)))\n",
    "print('DIFERENCIA DE: {}%'.format(diferencia_porcentual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:21:15.913996Z",
     "start_time": "2021-03-15T23:21:15.901181Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se crea un dataframe con los resultados\n",
    "resultados_train = pd.DataFrame({'TYPE': ['TRAIN']*len(Y_train), 'TRUE': Y_train, 'PREDICTED': train_predictions})\n",
    "resultados_test = pd.DataFrame({'TYPE': ['TEST']*len(Y_test), 'TRUE': Y_test, 'PREDICTED': test_predictions})\n",
    "resultados_nn = pd.concat([resultados_train, resultados_test], axis=0).reset_index(drop=True)\n",
    "resultados_nn['ABSOLUTE_ERROR'] = (resultados_nn['TRUE']-resultados_nn['PREDICTED']).abs()\n",
    "resultados_nn['SQUARE_ERROR'] = (resultados_nn['TRUE']-resultados_nn['PREDICTED'])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:21:16.698411Z",
     "start_time": "2021-03-15T23:21:16.689731Z"
    }
   },
   "outputs": [],
   "source": [
    "# Resultados por cantidad\n",
    "resultados_por_cantidad = resultados_nn.groupby(['TYPE', 'TRUE'])[['ABSOLUTE_ERROR', 'SQUARE_ERROR']].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:21:17.405994Z",
     "start_time": "2021-03-15T23:21:17.395645Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TYPE</th>\n",
       "      <th>TRUE</th>\n",
       "      <th>ABSOLUTE_ERROR</th>\n",
       "      <th>SQUARE_ERROR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST</td>\n",
       "      <td>0</td>\n",
       "      <td>32.572327</td>\n",
       "      <td>1091.150943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST</td>\n",
       "      <td>1</td>\n",
       "      <td>31.567164</td>\n",
       "      <td>1077.268657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST</td>\n",
       "      <td>2</td>\n",
       "      <td>30.506494</td>\n",
       "      <td>1005.077922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST</td>\n",
       "      <td>3</td>\n",
       "      <td>32.562500</td>\n",
       "      <td>1650.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST</td>\n",
       "      <td>4</td>\n",
       "      <td>27.738462</td>\n",
       "      <td>782.169231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TEST</td>\n",
       "      <td>5</td>\n",
       "      <td>37.769106</td>\n",
       "      <td>2408.884553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TEST</td>\n",
       "      <td>6</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>8836.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TEST</td>\n",
       "      <td>7</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>8649.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TEST</td>\n",
       "      <td>8</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>729.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TEST</td>\n",
       "      <td>14</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>2025.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TEST</td>\n",
       "      <td>25</td>\n",
       "      <td>35.348214</td>\n",
       "      <td>2749.839286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TEST</td>\n",
       "      <td>50</td>\n",
       "      <td>38.716094</td>\n",
       "      <td>3252.368897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TEST</td>\n",
       "      <td>56</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>8836.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TEST</td>\n",
       "      <td>100</td>\n",
       "      <td>50.536023</td>\n",
       "      <td>4336.599424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TEST</td>\n",
       "      <td>150</td>\n",
       "      <td>51.550218</td>\n",
       "      <td>4097.890830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TEST</td>\n",
       "      <td>200</td>\n",
       "      <td>71.705128</td>\n",
       "      <td>8198.346154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TEST</td>\n",
       "      <td>250</td>\n",
       "      <td>70.143389</td>\n",
       "      <td>10361.778399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TEST</td>\n",
       "      <td>500</td>\n",
       "      <td>227.262376</td>\n",
       "      <td>67745.268977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TYPE  TRUE  ABSOLUTE_ERROR  SQUARE_ERROR\n",
       "0   TEST     0       32.572327   1091.150943\n",
       "1   TEST     1       31.567164   1077.268657\n",
       "2   TEST     2       30.506494   1005.077922\n",
       "3   TEST     3       32.562500   1650.562500\n",
       "4   TEST     4       27.738462    782.169231\n",
       "5   TEST     5       37.769106   2408.884553\n",
       "6   TEST     6       94.000000   8836.000000\n",
       "7   TEST     7       93.000000   8649.000000\n",
       "8   TEST     8       27.000000    729.000000\n",
       "9   TEST    14       45.000000   2025.000000\n",
       "10  TEST    25       35.348214   2749.839286\n",
       "11  TEST    50       38.716094   3252.368897\n",
       "12  TEST    56       94.000000   8836.000000\n",
       "13  TEST   100       50.536023   4336.599424\n",
       "14  TEST   150       51.550218   4097.890830\n",
       "15  TEST   200       71.705128   8198.346154\n",
       "16  TEST   250       70.143389  10361.778399\n",
       "17  TEST   500      227.262376  67745.268977"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprime los resultados por cantidad en cuanto al MAE y MSE para los datos de prueba\n",
    "resultados_por_cantidad.loc[resultados_por_cantidad['TYPE']=='TEST']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análisis de Resultados y Rendimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de correr un `MLP` con una arquitectura muy simple (algunas capas intermedias con activación `relu` y `dropout`) se usa el modelo para mirar como predice tanto en el entrenamiento como en la prueba y los resultados de manera general son:\n",
    "\n",
    "\n",
    "* Métricas del modelo:\n",
    "    |       | RMSE | MAE   |\n",
    "    | :---        |    ----:   |          ---: |\n",
    "    | ENTRENAMIENTO      |    101.38    |   67.57     |\n",
    "    | PRUEBA   |    112.71      |    75.05   |\n",
    "    | DIFERENCIA PORCENTUAL   |    11.17%     |    11.07%    |\n",
    "    \n",
    "    Se puede que realmente hay un overfitting mucho menor en porcentualidad al encontrado en el algoritmo `XGBoost`. El error promedio (mírese el RMSE and MAE) es realmente alto, por ejemplo, en promedio se tiene un MAE de 75.05 unidades vendidas!\n",
    "\n",
    "    De nuevo, después de hacer la aproximación, los resultados mejoraron un poco: \n",
    "    \n",
    "    |       | RMSE | MAE   |\n",
    "    | :---        |    ----:   |          ---: |\n",
    "    | ENTRENAMIENTO      |    110.47    |   68.29     |\n",
    "    | PRUEBA   |    118.93      |   74.07    |\n",
    "    | DIFERENCIA PORCENTUAL   |    7.66%      |   8.47%   |\n",
    "    * con aproximación\n",
    "    \n",
    "    De manera general el MAE bajo y el RMSE subió. Para ambos tipos de errores con la diferencia porcentual el overfitting bajó un poco.\n",
    "    \n",
    "\n",
    "* Si miramos los errores para cada cantidad vendida en los valores reales se puede ver que los errores promedio son más similares con respecto a lo obtenido con el `XGBoost`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest (Bosques Aleatorios)\n",
    "\n",
    "Uno de los algoritmos que escogí para usar es Bosques Aleatorios utilizando `ScikitLearn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T01:34:48.560482Z",
     "start_time": "2021-03-16T01:34:02.479230Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   15.4s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   42.9s finished\n"
     ]
    }
   ],
   "source": [
    "# Diccionario de hiperparametros a tunear\n",
    "param_tuning = {'n_estimators': [100],\n",
    "               'max_features': ['sqrt', 'log2'],\n",
    "               'max_depth': [7, 10],\n",
    "               'min_samples_leaf': [2, 4],\n",
    "               'min_samples_split': [5, 10],\n",
    "               'bootstrap': [False]}\n",
    "\n",
    "# Se evalua para todas las combinaciones de hiperparametros cual tiene el menor error de validacion\n",
    "# usando validacion cruzada para 5-folds\n",
    "\n",
    "# Modelo RFRegressor\n",
    "rf_model = RandomForestRegressor(random_state=1608)\n",
    "\n",
    "# Validacion cruzada\n",
    "k_folds = KFold(n_splits=5, shuffle=True, random_state=1608)\n",
    "grid_search_cv = GridSearchCV(estimator = rf_model,\n",
    "                              param_grid = param_tuning,            \n",
    "                              cv = k_folds,\n",
    "                              n_jobs = -1,\n",
    "                              verbose = 1)\n",
    "cv_fit = grid_search_cv.fit(X=X_train_total, y=Y_train) # Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T01:34:48.566129Z",
     "start_time": "2021-03-16T01:34:48.562730Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'max_depth': 10,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprime los mejores parametros bajo el score de cv calculado para cada iteracion\n",
    "grid_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T01:34:48.751153Z",
     "start_time": "2021-03-16T01:34:48.568584Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se generan las predicciones para el entrenamiento y prueba y se evaluan dos metricas: RMSE y MAE\n",
    "rf_best_model = grid_search_cv.best_estimator_\n",
    "test_predictions = rf_best_model.predict(X_test_total)\n",
    "train_predictions = rf_best_model.predict(X_train_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T01:34:48.758690Z",
     "start_time": "2021-03-16T01:34:48.753538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE DE ENTRENAMIENTO: 137.27\n",
      "RMSE DE PRUEBA: 139.83\n",
      "DIFERENCIA DE: 1.86%\n"
     ]
    }
   ],
   "source": [
    "# Comparacion RSME train y test\n",
    "rmse_train = np.sqrt(mean_squared_error(y_pred=train_predictions, y_true=Y_train))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_pred=test_predictions, y_true=Y_test))\n",
    "print('RMSE DE ENTRENAMIENTO: {}'.format(np.round(rmse_train,2)))\n",
    "print('RMSE DE PRUEBA: {}'.format(np.round(rmse_test,2)))\n",
    "diferencia_porcentual = np.round(100*(rmse_test-rmse_train)/rmse_train,2)\n",
    "print('DIFERENCIA DE: {}%'.format(diferencia_porcentual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T01:34:48.765923Z",
     "start_time": "2021-03-16T01:34:48.760441Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE DE ENTRENAMIENTO: 108.64\n",
      "MAE DE PRUEBA: 111.3\n",
      "DIFERENCIA DE: 2.44%\n"
     ]
    }
   ],
   "source": [
    "# Comparacion MAE train y test\n",
    "mae_train = mean_absolute_error(y_pred=train_predictions, y_true=Y_train)\n",
    "mae_test = mean_absolute_error(y_pred=test_predictions, y_true=Y_test)\n",
    "diferencia_porcentual = np.round(100*(mae_test-mae_train)/mae_train,2)\n",
    "print('MAE DE ENTRENAMIENTO: {}'.format(np.round(mae_train,2)))\n",
    "print('MAE DE PRUEBA: {}'.format(np.round(mae_test,2)))\n",
    "print('DIFERENCIA DE: {}%'.format(diferencia_porcentual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:46:08.115749Z",
     "start_time": "2021-03-15T23:46:08.018019Z"
    }
   },
   "outputs": [],
   "source": [
    "values = sorted(Y_train.unique())\n",
    "test_predictions = [find_nearest(values, p)for p in test_predictions] \n",
    "train_predictions = [find_nearest(values, p)for p in train_predictions] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:46:08.537736Z",
     "start_time": "2021-03-15T23:46:08.531467Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE DE ENTRENAMIENTO: 140.18\n",
      "RMSE DE PRUEBA: 142.21\n",
      "DIFERENCIA DE: 1.45%\n"
     ]
    }
   ],
   "source": [
    "# Comparacion RSME train y test\n",
    "rmse_train = np.sqrt(mean_squared_error(y_pred=train_predictions, y_true=Y_train))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_pred=test_predictions, y_true=Y_test))\n",
    "print('RMSE DE ENTRENAMIENTO: {}'.format(np.round(rmse_train,2)))\n",
    "print('RMSE DE PRUEBA: {}'.format(np.round(rmse_test,2)))\n",
    "diferencia_porcentual = np.round(100*(rmse_test-rmse_train)/rmse_train,2)\n",
    "print('DIFERENCIA DE: {}%'.format(diferencia_porcentual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:46:09.508120Z",
     "start_time": "2021-03-15T23:46:09.502080Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE DE ENTRENAMIENTO: 109.64\n",
      "MAE DE PRUEBA: 111.57\n",
      "DIFERENCIA DE: 1.76%\n"
     ]
    }
   ],
   "source": [
    "# Comparacion MAE train y test\n",
    "mae_train = mean_absolute_error(y_pred=train_predictions, y_true=Y_train)\n",
    "mae_test = mean_absolute_error(y_pred=test_predictions, y_true=Y_test)\n",
    "diferencia_porcentual = np.round(100*(mae_test-mae_train)/mae_train,2)\n",
    "print('MAE DE ENTRENAMIENTO: {}'.format(np.round(mae_train,2)))\n",
    "print('MAE DE PRUEBA: {}'.format(np.round(mae_test,2)))\n",
    "print('DIFERENCIA DE: {}%'.format(diferencia_porcentual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:46:10.339030Z",
     "start_time": "2021-03-15T23:46:10.325663Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se crea un dataframe con los resultados\n",
    "resultados_train = pd.DataFrame({'TYPE': ['TRAIN']*len(Y_train), 'TRUE': Y_train, 'PREDICTED': train_predictions})\n",
    "resultados_test = pd.DataFrame({'TYPE': ['TEST']*len(Y_test), 'TRUE': Y_test, 'PREDICTED': test_predictions})\n",
    "resultados_rf = pd.concat([resultados_train, resultados_test], axis=0).reset_index(drop=True)\n",
    "resultados_rf['ABSOLUTE_ERROR'] = (resultados_rf['TRUE']-resultados_rf['PREDICTED']).abs()\n",
    "resultados_rf['SQUARE_ERROR'] = (resultados_rf['TRUE']-resultados_rf['PREDICTED'])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:46:10.983066Z",
     "start_time": "2021-03-15T23:46:10.974115Z"
    }
   },
   "outputs": [],
   "source": [
    "# Resultados por cantidad\n",
    "resultados_por_cantidad = resultados_rf.groupby(['TYPE', 'TRUE'])[['ABSOLUTE_ERROR', 'SQUARE_ERROR']].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:46:11.634751Z",
     "start_time": "2021-03-15T23:46:11.624196Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TYPE</th>\n",
       "      <th>TRUE</th>\n",
       "      <th>ABSOLUTE_ERROR</th>\n",
       "      <th>SQUARE_ERROR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST</td>\n",
       "      <td>0</td>\n",
       "      <td>65.811321</td>\n",
       "      <td>5248.113208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST</td>\n",
       "      <td>1</td>\n",
       "      <td>75.238806</td>\n",
       "      <td>6200.194030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST</td>\n",
       "      <td>2</td>\n",
       "      <td>82.038961</td>\n",
       "      <td>7453.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST</td>\n",
       "      <td>3</td>\n",
       "      <td>81.541667</td>\n",
       "      <td>7255.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST</td>\n",
       "      <td>4</td>\n",
       "      <td>81.938462</td>\n",
       "      <td>7408.707692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TEST</td>\n",
       "      <td>5</td>\n",
       "      <td>105.443902</td>\n",
       "      <td>12439.856911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TEST</td>\n",
       "      <td>6</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>14786.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TEST</td>\n",
       "      <td>7</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>8649.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TEST</td>\n",
       "      <td>8</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>20164.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TEST</td>\n",
       "      <td>14</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>7396.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TEST</td>\n",
       "      <td>25</td>\n",
       "      <td>103.375000</td>\n",
       "      <td>11818.209821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TEST</td>\n",
       "      <td>50</td>\n",
       "      <td>92.593128</td>\n",
       "      <td>9869.775769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TEST</td>\n",
       "      <td>56</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>8836.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TEST</td>\n",
       "      <td>100</td>\n",
       "      <td>55.778098</td>\n",
       "      <td>4570.331412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TEST</td>\n",
       "      <td>150</td>\n",
       "      <td>26.816594</td>\n",
       "      <td>1662.799127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TEST</td>\n",
       "      <td>200</td>\n",
       "      <td>39.102564</td>\n",
       "      <td>2564.102564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TEST</td>\n",
       "      <td>250</td>\n",
       "      <td>63.314711</td>\n",
       "      <td>5623.836127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TEST</td>\n",
       "      <td>500</td>\n",
       "      <td>291.899340</td>\n",
       "      <td>86834.952145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TYPE  TRUE  ABSOLUTE_ERROR  SQUARE_ERROR\n",
       "0   TEST     0       65.811321   5248.113208\n",
       "1   TEST     1       75.238806   6200.194030\n",
       "2   TEST     2       82.038961   7453.545455\n",
       "3   TEST     3       81.541667   7255.958333\n",
       "4   TEST     4       81.938462   7408.707692\n",
       "5   TEST     5      105.443902  12439.856911\n",
       "6   TEST     6      119.000000  14786.000000\n",
       "7   TEST     7       93.000000   8649.000000\n",
       "8   TEST     8      142.000000  20164.000000\n",
       "9   TEST    14       86.000000   7396.000000\n",
       "10  TEST    25      103.375000  11818.209821\n",
       "11  TEST    50       92.593128   9869.775769\n",
       "12  TEST    56       94.000000   8836.000000\n",
       "13  TEST   100       55.778098   4570.331412\n",
       "14  TEST   150       26.816594   1662.799127\n",
       "15  TEST   200       39.102564   2564.102564\n",
       "16  TEST   250       63.314711   5623.836127\n",
       "17  TEST   500      291.899340  86834.952145"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprime los resultados por cantidad en cuanto al MAE y MSE para los datos de prueba\n",
    "resultados_por_cantidad.loc[resultados_por_cantidad['TYPE']=='TEST']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análisis de Resultados y Rendimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de escoger por la validación cruzada los hiper-parámetros del `RandomForestRegressor` se usa el modelo para mirar como predice tanto en el entrenamiento como en la prueba y los resultados de manera general son:\n",
    "\n",
    "* Métricas del modelo:\n",
    "    |       | RMSE | MAE   |\n",
    "    | :---        |    ----:   |          ---: |\n",
    "    | ENTRENAMIENTO      |    137.27    |   108.64     |\n",
    "    | PRUEBA   |    139.83      |    111.3   |\n",
    "    | DIFERENCIA PORCENTUAL   |    1.86%     |    2.44%    |\n",
    "    \n",
    "    Se puede que realmente hay un overfitting mucho menor en porcentualidad al encontrado en los algoritmos anterior. Sin embargo, el error promedio (mírese el RMSE and MAE) es demasiado altos: en promedio se tiene un MAE de 108.64 unidades vendidas, más de 100 unidades vendidas!\n",
    "\n",
    "    De nuevo, después de hacer la aproximación, los resultados mejoraron un poco: \n",
    "    \n",
    "    |       | RMSE | MAE   |\n",
    "    | :---        |    ----:   |          ---: |\n",
    "    | ENTRENAMIENTO      |    140.18    |   109.64     |\n",
    "    | PRUEBA   |    142.21      |   111.57    |\n",
    "    | DIFERENCIA PORCENTUAL   |    1.45%      |   1.76%  |\n",
    "    * con aproximación\n",
    "\n",
    "    De manera general el MAE bajo y el RMSE subió. Para ambos tipos de errores con la diferencia porcentual el overfitting bajó un poco.\n",
    "    \n",
    "\n",
    "* Si miramos los errores para cada cantidad vendida en los valores reales se puede ver que los errores promedio son mucho peores que los registrados en los anteriores modelos.\n",
    "\n",
    "Este fue el peor de los algoritmos evaluados por las métricas de error, además de ser el que más tiempo tomó (y eso que la validación cruzada se hizo para muy pocas combinaciones de parámetros). Eso sí, creo que faltó poner muchos parámetros como `max_depth` con mayor complejidad, es decir permitir árboles más extensos en general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked Model\n",
    "\n",
    "Una idea final que tuve para lograr el mejor modelo posible dentro del tiempo que tenía para experimentar con los datos fue hacer un modelo que a partir de las predicciones de los tres modelos presentados anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:46:34.163686Z",
     "start_time": "2021-03-15T23:46:34.149717Z"
    }
   },
   "outputs": [],
   "source": [
    "# Construccion de dataset de predicciones\n",
    "resultados = resultados_xgb[['TYPE', 'TRUE', 'PREDICTED']].rename(columns={'PREDICTED': 'PREDICTED_XGB'})\n",
    "resultados['PREDICTED_NN'] = resultados_nn['PREDICTED']\n",
    "resultados['PREDICTED_RF'] = resultados_rf['PREDICTED']\n",
    "\n",
    "# Separa en train y test\n",
    "X_train_stack = resultados.loc[resultados['TYPE']=='TRAIN'].drop(columns=['TYPE', 'TRUE'])\n",
    "X_test_stack = resultados.loc[resultados['TYPE']=='TEST'].drop(columns=['TYPE', 'TRUE'])\n",
    "Y_train_stack = resultados.loc[resultados['TYPE']=='TRAIN', 'TRUE'] \n",
    "Y_test_stack = resultados.loc[resultados['TYPE']=='TEST', 'TRUE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:46:46.142076Z",
     "start_time": "2021-03-15T23:46:35.186214Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   10.8s finished\n"
     ]
    }
   ],
   "source": [
    "# Diccionario de hiperparametros a tunear\n",
    "param_tuning = {'n_estimators': [100, 1000],\n",
    "               'max_features': ['auto', 'sqrt'],\n",
    "               'max_depth': [3, 5, 7, 10],\n",
    "               'bootstrap': [False]}\n",
    "\n",
    "# Se evalua para todas las combinaciones de hiperparametros cual tiene el menor error de validacion\n",
    "# usando validacion cruzada para 5-folds\n",
    "\n",
    "# Modelo RFRegressor\n",
    "rf_stack_model = RandomForestRegressor(random_state=1608)\n",
    "\n",
    "# Validacion cruzada\n",
    "k_folds = KFold(n_splits=5, shuffle=True, random_state=1608)\n",
    "grid_search_cv = GridSearchCV(estimator = rf_model,\n",
    "                              param_grid = param_tuning,            \n",
    "                              cv = k_folds,\n",
    "                              n_jobs = -1,\n",
    "                              verbose = 1)\n",
    "cv_fit = grid_search_cv.fit(X=X_train_stack, y=Y_train_stack) # Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:46:47.943600Z",
     "start_time": "2021-03-15T23:46:47.940027Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'max_depth': 7,\n",
       " 'max_features': 'sqrt',\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprime los mejores parametros bajo el score de cv calculado para cada iteracion\n",
    "grid_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:46:49.286200Z",
     "start_time": "2021-03-15T23:46:49.201342Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se generan las predicciones para el entrenamiento y prueba y se evaluan dos metricas: RMSE y MAE\n",
    "rf_stack_best_model = grid_search_cv.best_estimator_\n",
    "test_predictions = rf_stack_best_model.predict(X_test_stack)\n",
    "train_predictions = rf_stack_best_model.predict(X_train_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:46:49.904503Z",
     "start_time": "2021-03-15T23:46:49.899346Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE DE ENTRENAMIENTO: 75.7\n",
      "RMSE DE PRUEBA: 104.95\n",
      "DIFERENCIA DE: 38.65%\n"
     ]
    }
   ],
   "source": [
    "# Comparacion RSME train y test\n",
    "rmse_train = np.sqrt(mean_squared_error(y_pred=train_predictions, y_true=Y_train))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_pred=test_predictions, y_true=Y_test))\n",
    "print('RMSE DE ENTRENAMIENTO: {}'.format(np.round(rmse_train,2)))\n",
    "print('RMSE DE PRUEBA: {}'.format(np.round(rmse_test,2)))\n",
    "diferencia_porcentual = np.round(100*(rmse_test-rmse_train)/rmse_train,2)\n",
    "print('DIFERENCIA DE: {}%'.format(diferencia_porcentual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:46:54.155017Z",
     "start_time": "2021-03-15T23:46:54.149964Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE DE ENTRENAMIENTO: 47.91\n",
      "MAE DE PRUEBA: 67.06\n",
      "DIFERENCIA DE: 39.98%\n"
     ]
    }
   ],
   "source": [
    "# Comparacion MAE train y test\n",
    "mae_train = mean_absolute_error(y_pred=train_predictions, y_true=Y_train)\n",
    "mae_test = mean_absolute_error(y_pred=test_predictions, y_true=Y_test)\n",
    "diferencia_porcentual = np.round(100*(mae_test-mae_train)/mae_train,2)\n",
    "print('MAE DE ENTRENAMIENTO: {}'.format(np.round(mae_train,2)))\n",
    "print('MAE DE PRUEBA: {}'.format(np.round(mae_test,2)))\n",
    "print('DIFERENCIA DE: {}%'.format(diferencia_porcentual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:46:56.051217Z",
     "start_time": "2021-03-15T23:46:55.950839Z"
    }
   },
   "outputs": [],
   "source": [
    "values = sorted(Y_train.unique())\n",
    "test_predictions = [find_nearest(values, p)for p in test_predictions] \n",
    "train_predictions = [find_nearest(values, p)for p in train_predictions] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:46:56.541243Z",
     "start_time": "2021-03-15T23:46:56.534988Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE DE ENTRENAMIENTO: 82.66\n",
      "RMSE DE PRUEBA: 111.73\n",
      "DIFERENCIA DE: 35.17%\n"
     ]
    }
   ],
   "source": [
    "# Comparacion RSME train y test\n",
    "rmse_train = np.sqrt(mean_squared_error(y_pred=train_predictions, y_true=Y_train))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_pred=test_predictions, y_true=Y_test))\n",
    "print('RMSE DE ENTRENAMIENTO: {}'.format(np.round(rmse_train,2)))\n",
    "print('RMSE DE PRUEBA: {}'.format(np.round(rmse_test,2)))\n",
    "diferencia_porcentual = np.round(100*(rmse_test-rmse_train)/rmse_train,2)\n",
    "print('DIFERENCIA DE: {}%'.format(diferencia_porcentual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:46:57.284327Z",
     "start_time": "2021-03-15T23:46:57.278388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE DE ENTRENAMIENTO: 43.99\n",
      "MAE DE PRUEBA: 64.83\n",
      "DIFERENCIA DE: 47.38%\n"
     ]
    }
   ],
   "source": [
    "# Comparacion MAE train y test\n",
    "mae_train = mean_absolute_error(y_pred=train_predictions, y_true=Y_train)\n",
    "mae_test = mean_absolute_error(y_pred=test_predictions, y_true=Y_test)\n",
    "diferencia_porcentual = np.round(100*(mae_test-mae_train)/mae_train,2)\n",
    "print('MAE DE ENTRENAMIENTO: {}'.format(np.round(mae_train,2)))\n",
    "print('MAE DE PRUEBA: {}'.format(np.round(mae_test,2)))\n",
    "print('DIFERENCIA DE: {}%'.format(diferencia_porcentual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:46:59.095131Z",
     "start_time": "2021-03-15T23:46:59.081466Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se crea un dataframe con los resultados\n",
    "resultados_train = pd.DataFrame({'TYPE': ['TRAIN']*len(Y_train), 'TRUE': Y_train, 'PREDICTED': train_predictions})\n",
    "resultados_test = pd.DataFrame({'TYPE': ['TEST']*len(Y_test), 'TRUE': Y_test, 'PREDICTED': test_predictions})\n",
    "resultados_rf = pd.concat([resultados_train, resultados_test], axis=0).reset_index(drop=True)\n",
    "resultados_rf['ABSOLUTE_ERROR'] = (resultados_rf['TRUE']-resultados_rf['PREDICTED']).abs()\n",
    "resultados_rf['SQUARE_ERROR'] = (resultados_rf['TRUE']-resultados_rf['PREDICTED'])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:46:59.874773Z",
     "start_time": "2021-03-15T23:46:59.865839Z"
    }
   },
   "outputs": [],
   "source": [
    "# Resultados por cantidad\n",
    "resultados_por_cantidad = resultados_rf.groupby(['TYPE', 'TRUE'])[['ABSOLUTE_ERROR', 'SQUARE_ERROR']].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:47:00.709532Z",
     "start_time": "2021-03-15T23:47:00.698532Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TYPE</th>\n",
       "      <th>TRUE</th>\n",
       "      <th>ABSOLUTE_ERROR</th>\n",
       "      <th>SQUARE_ERROR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST</td>\n",
       "      <td>0</td>\n",
       "      <td>8.710692</td>\n",
       "      <td>176.283019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST</td>\n",
       "      <td>1</td>\n",
       "      <td>10.164179</td>\n",
       "      <td>313.208955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST</td>\n",
       "      <td>2</td>\n",
       "      <td>7.909091</td>\n",
       "      <td>129.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST</td>\n",
       "      <td>3</td>\n",
       "      <td>11.354167</td>\n",
       "      <td>442.020833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST</td>\n",
       "      <td>4</td>\n",
       "      <td>7.646154</td>\n",
       "      <td>159.492308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TEST</td>\n",
       "      <td>5</td>\n",
       "      <td>26.447154</td>\n",
       "      <td>2231.744715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TEST</td>\n",
       "      <td>6</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>5386.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TEST</td>\n",
       "      <td>7</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>2304.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TEST</td>\n",
       "      <td>8</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>225.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TEST</td>\n",
       "      <td>14</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>289.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TEST</td>\n",
       "      <td>25</td>\n",
       "      <td>38.232143</td>\n",
       "      <td>3707.263393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TEST</td>\n",
       "      <td>50</td>\n",
       "      <td>51.737794</td>\n",
       "      <td>6026.287523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TEST</td>\n",
       "      <td>56</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>1936.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TEST</td>\n",
       "      <td>100</td>\n",
       "      <td>71.368876</td>\n",
       "      <td>10630.792507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TEST</td>\n",
       "      <td>150</td>\n",
       "      <td>72.834061</td>\n",
       "      <td>11148.414847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TEST</td>\n",
       "      <td>200</td>\n",
       "      <td>79.346154</td>\n",
       "      <td>10707.512821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TEST</td>\n",
       "      <td>250</td>\n",
       "      <td>86.249534</td>\n",
       "      <td>16807.702048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TEST</td>\n",
       "      <td>500</td>\n",
       "      <td>144.503300</td>\n",
       "      <td>41973.665017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TYPE  TRUE  ABSOLUTE_ERROR  SQUARE_ERROR\n",
       "0   TEST     0        8.710692    176.283019\n",
       "1   TEST     1       10.164179    313.208955\n",
       "2   TEST     2        7.909091    129.285714\n",
       "3   TEST     3       11.354167    442.020833\n",
       "4   TEST     4        7.646154    159.492308\n",
       "5   TEST     5       26.447154   2231.744715\n",
       "6   TEST     6       69.000000   5386.000000\n",
       "7   TEST     7       48.000000   2304.000000\n",
       "8   TEST     8       15.000000    225.000000\n",
       "9   TEST    14       17.000000    289.000000\n",
       "10  TEST    25       38.232143   3707.263393\n",
       "11  TEST    50       51.737794   6026.287523\n",
       "12  TEST    56       44.000000   1936.000000\n",
       "13  TEST   100       71.368876  10630.792507\n",
       "14  TEST   150       72.834061  11148.414847\n",
       "15  TEST   200       79.346154  10707.512821\n",
       "16  TEST   250       86.249534  16807.702048\n",
       "17  TEST   500      144.503300  41973.665017"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprime los resultados por cantidad en cuanto al MAE y MSE para los datos de prueba\n",
    "resultados_por_cantidad.loc[resultados_por_cantidad['TYPE']=='TEST']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análisis de Resultados y Rendimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hizo un _stacking_ o apilamiento de las predicciones de los modelos usados y se usó como modelo un simple `RandomForestRegressor` y obtuvieron los siguientes resultados:\n",
    "\n",
    "* Métricas del modelo:\n",
    "    |       | RMSE | MAE   |\n",
    "    | :---        |    ----:   |          ---: |\n",
    "    | ENTRENAMIENTO      |    75.7    |   47.91     |\n",
    "    | PRUEBA   |    104.95      |    67.06   |\n",
    "    | DIFERENCIA PORCENTUAL   |    38.65%     |    39.98%    |\n",
    "    \n",
    "    A pesar de haber un overfitting notable, es claro que, sin contar los resultados de aproximación, el __Stack Model__ es el que mejores métricas de error tiene.\n",
    "\n",
    "    De nuevo, después de hacer la aproximación, los resultados mejoraron un poco: \n",
    "    \n",
    "    |       | RMSE | MAE   |\n",
    "    | :---        |    ----:   |          ---: |\n",
    "    | ENTRENAMIENTO      |    82.66    |   43.99     |\n",
    "    | PRUEBA   |    111.73      |   64.83    |\n",
    "    | DIFERENCIA PORCENTUAL   |    35.17%      |   47.38%  |\n",
    "    * con aproximación\n",
    "\n",
    "    A pesar de tener un overfitting fuerte (no corregido por la aproximación) si es el modelo o la predicción con las mejores métricas de error.\n",
    "    \n",
    "* Si miramos los errores para cada cantidad vendida en los valores reales se puede ver que sigue los mismos comportamientos que el `XGBoost`.\n",
    "\n",
    "Este fue el mejor de los algoritmos evaluados por las métricas de error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones y Reflexiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que se debe resaltar es la dificultad tan fuerte en generar un modelo que estime cuando se tiene una variedad tan diferente de ítems, vendedores y demás, sin mencionar que el conjunto de datos no es más que una muestra (y no comprende el total de ítems de [Mercado Libre Colombia](https://www.mercadolibre.com.co/)). \n",
    "\n",
    "Otro aspecto que creo que puede ser muy relevante es que tal vez, por la construcción del dataset, se tienen muchos ítems pérdidos en el MarketPlace (con un parámetro `offset` muy alto) y tal vez estos esten haciendo algún tipo de ruido en el modelo.\n",
    "\n",
    "El modelo construido usando el concepto de stack/apilar efectivamente resulta ser el mejor cuando se examinan las métricas (de prueba) de RMSE y MAE, lo cual para mí tiene mucho sentido pues junta y combina la __información__ (las predicciones) de cada uno de los modelos individuales. \n",
    "\n",
    "La cantidad vendida realmente corresponde a un set de rangos establecidos [aquí](https://developers.mercadolibre.com.ar/en_us/items-and-searches) y además algunos ítems tienen valores que no se presentan en el cuadro que muestra los valores de `sold_quantity` y por lo tanto, hay que añadir que por eso hay un poco de ruído en la variable de respuesta. El problema es demasiado retador y sería interesante ver que resultasdos se obtiene con mucho más tiempo y conocimiento del marketplace y de las features.\n",
    "\n",
    "Veo un potencial en construir algunas variables (feature engineering) con un poco más de tiempo e imaginación, además de usar tanto el texto del ítem como la imagen de este que efectivamente se puede obtener con la información del conjunto de datos (ver el código anexo). Sin embargo, el uso de imágenes y texto requeriría una muestra más grande de productos (tal vez de otros países también).\n",
    "\n",
    "_Una posibilidad_...\n",
    "\n",
    "__Modelo Alternativo.__ Se propone es trabajar con rangos de `ITEM_SOLD_QUANTITY`. Por ejemplo, se podrían usar los siguientes rangos (que serán tomados como clases):\n",
    "\n",
    "1. 0-50: De 0 a 50 cantdiades vendidas.\n",
    "2. 51-100: De 51 a 100 cantdiades vendidas.\n",
    "3. 101-150: De 101 a 150 cantdiades vendidas.\n",
    "4. 151-200: De 151 a 200 cantdiades vendidas.\n",
    "5. 201-250: De 201 a 250 cantdiades vendidas.\n",
    "6. 251-500: De 251 a 500 cantdiades vendidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T05:05:48.754898Z",
     "start_time": "2021-03-15T05:05:48.702352Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DESCARGADA IMAGEN DE: LLAVERO LUJO TRENZA CUERO MARCA TOYOTA PRADO TXL FORTU CRUIS\n"
     ]
    }
   ],
   "source": [
    "# Descarga la imagen con la url de un item\n",
    "img_url_example = products.loc[1608, 'ITEM_THUMBNAIL']\n",
    "response = requests.get(img_url_example)\n",
    "\n",
    "# Guarda la imagen\n",
    "print('DESCARGADA IMAGEN DE: {}'.format(products.loc[1608, 'ITEM_TITLE'].upper()))\n",
    "file = open(\"../Data/Images/EXAMPLE.png\", \"wb\")\n",
    "file.write(response.content)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../Data/Images/EXAMPLE.png \" alt=\"drawing\" width=\"200\" title='Ejemplo de la miniatura de un ítem'/>\n",
    "<center>  <font size=\"1\"> Ejemplo de la miniatura de un ítem del market place de Mercado Libre Colombia</font> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fin del Documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "notify_time": "10",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "461.989px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
